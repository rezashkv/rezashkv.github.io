---
title: "From Pixels to Prose: A Large Dataset of Dense Image Captions"
collection: publications
permalink: /publications/pixelprose/
excerpt: 'PixelProse is a comprehensive dataset of over 16M (million) synthetically generated captions, leveraging cutting-edge vision-language models for detailed and accurate descriptions.'
date: 2024-06-14
venue: 'ArXiv'
paperurl: 'https://arxiv.org/abs/2406.10328'
githuburl: 'https://huggingface.co/datasets/tomg-group-umd/pixelprose'
authors: 'Vasu Singla, Kaiyu Yue, Sukriti Paul, Reza Shirkavand, Mayuka Jayawardhana, Alireza Ganjdanesh, Heng Huang, Abhinav Bhatele, Gowthami Somepalli, Tom Goldstein'
#citation: "[Bibtex](https://scholar.googleusercontent.com/scholar.bib?q=info:ZkCwRc5-7bgJ:scholar.google.com/&output=citation&scisdr=ClExa795EPesk0nPEiI:AFWwaeYAAAAAZv7JCiJJwHMa3sda3gsFkNG24VI&scisig=AFWwaeYAAAAAZv7JCuMjfKl65zI00CI_v1C_Qlk&scisf=4&ct=citation&cd=-1&hl=en)" 
---
Training large vision-language models requires extensive, high-quality image-text pairs. Existing web-scraped datasets, however, are noisy and lack detailed image descriptions. To bridge this gap, we introduce PixelProse, a comprehensive dataset of over 16M (million) synthetically generated captions, leveraging cutting-edge vision-language models for detailed and accurate descriptions. To ensure data integrity, we rigorously analyze our dataset for problematic content, including child sexual abuse material (CSAM), personally identifiable information (PII), and toxicity. We also provide valuable metadata such as watermark presence and aesthetic scores, aiding in further dataset filtering. We hope PixelProse will be a valuable resource for future vision-language research.
[Dataset](https://huggingface.co/datasets/tomg-group-umd/pixelprose), [Paper](https://arxiv.org/abs/2406.10328)

